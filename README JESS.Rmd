---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Jonkershoek streamflow forecasting

<!-- badges: start -->
<!-- badges: end -->

## Team members

Jess Howard
Jess Prevôst
Nicola Bredenkamp
Vernon Visser


```{r libraries}
library(tidyverse)
library(rjags)
```

The data was downloaded from SAEON.

--Step 1: Data Cleaning--

Data cleaning and exploratory visualization was performed on the daily streamflow data. Invalid or unrealistic values were converted to NA (negative temperatures below -50°C, humidity values that were zero or exceed realistic bounds, soil moisture readings that were too low or predate 2015, and streamflow values below 0.01). The data was reshaped into long format to visualize the temporal patterns and assess data quality. The cleaned daily streamflow datasets were saved as new .csv files for use in other code scripts.

--Step 2: Null Time-Series Model using JAGS--

The data was read in and the daily streamflow data plotted.The daily streamflow data was assigned the name "ddat", and the metadata as "dmdat".

```{r, eval = FALSE, echo = T, warning = FALSE}

# Read daily metadata
dmdat <- read_csv("data/metadata_daily_2025-07-09.csv")
# Read daily data
ddat <- read_csv("data/data_daily_cleaned.csv")

# Plot daily streamflow data with horizontal line showing flood threshold
ddat |> ggplot() +
  geom_line(aes(y = `Streamflow Ave`, x = as.Date(Date))) +
  geom_hline(aes(yintercept = 4.076)) +
  ggtitle("Langrivier daily streamflow") +
  xlab("Date") +
  ylab("Streamflow (Cubic metres per second)")


```

Withhold the data from the start of 2024 by making the streamflow data NA for the forecasting and validation steps.The calibration data was saved as a .csv file called "cal_ddat".

```{r, eval = FALSE, echo = T, warning = FALSE}

# Withhold data
cal_ddat <- ddat |> mutate(`Streamflow Ave` = ifelse(Date < "2024-01-01", `Streamflow Ave`, NA))
  filter(Date > "2013-03-16") # remove dates before 2013-03-16 where no rainfall data

```

The dates before 2013-03-16 where there is no rainfall data were removed. A one day set back lag was assumed between the rain falling and the streamflow increase.

```{r, eval = FALSE, echo = T, warning = FALSE}

# Remove dates before 2013-03-16 where there is no rainfall data
cal_ddat <- cal_ddat %>%
  filter(Date > "2013-03-16")

ddat <- ddat %>%
  filter(Date > "2013-03-16") 

# Need to move previous day's rainfall to current day 
cal_ddat <- cal_ddat %>%
  mutate(rainfall_dayback = lag(`Rainfall Total`, 1))

```

Data for the model was assigned.

```{r, eval = FALSE, echo = T, warning = FALSE}

# Format data for model
time <- cal_ddat$Date
y <- cal_ddat$`Streamflow Ave`
z <- ddat$`Streamflow Ave` # for plotting later
y_log <- log(y)
y_log[is.infinite(y_log)] <- NA

```

The null time-series model was determined and defined, then the model was called through JAGS and run.

```{r, eval = FALSE, echo = T, warning = FALSE}

# Define the model
RandomWalk <- "
model{
  
  #### Data Model
  for(t in 1:n){
    y[t] ~ dnorm(x[t],tau_obs)
  }
  
  #### Process Model (random walk)
  for(t in 2:n){
    x[t] ~ dnorm(x[t-1], tau_add)
  }

  #### Priors
  x[1] ~ dnorm(x_ic, tau_ic)
  tau_obs ~ dgamma(a_obs,r_obs) ## prior on observation error
  tau_add ~ dgamma(a_add,r_add) ## prior on process error
}
"

data <- list(y=y_log,n=length(y),      ## data
             x_ic=log(0.1),tau_ic=0.1,    ## initial condition prior
             a_obs=1,r_obs=1,           ## obs error prior
             a_add=1,r_add=1            ## process error prior
)

nchain = 3
# init <- list()
# for(i in 1:nchain){
#   y.samp = sample(y,length(y),replace=TRUE)
#   init[[i]] <- list(tau_add=1/var(diff(log(y.samp))),  ## initial guess on process precision
#                     tau_obs=5/var(log(y.samp)))        ## initial guess on obs precision

# Run the model
j.model   <- jags.model (file = textConnection(RandomWalk),
                         data = data,
                         # inits = init,
                         n.chains = 3)

```

The convergence was the checked.

```{r, eval = FALSE, echo = T, warning = FALSE}

# Sample from model without x to check that convergence has happened
jags.out   <- coda.samples (model = j.model,
                            variable.names = c("tau_add","tau_obs"),
                            n.iter = 5000)
# See if convergence has happened
plot(jags.out)

jags.out   <- coda.samples (model = j.model,
                            variable.names = c("x","tau_add","tau_obs"),
                            n.iter = 10000)

burnin = 1000                                   ## determine convergence
jags.burn <- window(jags.out, start = burnin)  ## remove burn-in

```

The data and confidence intervals were visualized.

```{r, eval = FALSE, echo = T, warning = FALSE}

# Plot data and confidence interval
time.rng = c(1,length(time))       ## adjust to zoom in and out
out <- as.matrix(jags.out)         ## convert from coda to matrix  
x.cols <- grep("^x",colnames(out)) ## grab all columns that start with the letter x
ci <- apply(exp(out[,x.cols]),2,quantile,c(0.025,0.5,0.975)) ## model was fit on log scale

plot(time,ci[2,],type='n',ylim=range(y,na.rm=TRUE),ylab="Streamflow average", log='y', xlim=time[time.rng])
## adjust x-axis label to be monthly if zoomed
if(diff(time.rng) < 100){ 
  axis.Date(1, at=seq(time[time.rng[1]],time[time.rng[2]],by='month'), format = "%Y-%m")
}
ecoforecastR::ciEnvelope(time,ci[1,],ci[3,],col=ecoforecastR::col.alpha("lightBlue",0.75)) # add confidence interval 
# add data points
included <- !is.na(y)
heldout <- is.na(y)
# Plot included data points (model saw these)
points(time[included], y[included], pch="+", col='black', cex=0.6)  # filled black dots
# Plot held-out data points (model did NOT see these)
points(time[heldout], z[heldout], pch=1, col='red', cex=0.8)       # open red circles 

```

--Step 3: Identifying the Co-variate--



```{r, eval = FALSE, echo = T, warning = FALSE}



```


--Step 4: Adding the Co-variate to the Model--



```{r, eval = FALSE, echo = T, warning = FALSE}

# Call the daily rainfall data used
rainfall_lag <- cal_ddat$rainfall_dayback 
rainfall_lag[is.na(rainfall_lag)] <- 0 # for now make NA values 0


# Define the model
Rainfall_RandomWalk <- "
model{
  
  #### Data Model
  for(t in 1:n){
    y[t] ~ dnorm(x[t],tau_obs)
  }
  
  #### Process Model (random walk)
  for(t in 2:n){
    x[t] ~ dnorm(x[t-1] + beta * c[t], tau_add)
  }

  #### Priors
  x[1] ~ dnorm(x_ic, tau_ic)
  beta ~ dnorm(0, 0.01) ## prior on the beta for rainfall
  tau_obs ~ dgamma(a_obs,r_obs) ## prior on observation error
  tau_add ~ dgamma(a_add,r_add) ## prior on process error
}
"

data <- list(y=y_log,n=length(y),      ## data
             c = rainfall_lag,  ## rainfall
             x_ic=log(0.1),tau_ic=0.1,    ## initial condition prior
             a_obs=1,r_obs=1,           ## obs error prior
             a_add=1,r_add=1            ## process error prior
)


# Run the model
j.model   <- jags.model (file = textConnection(Rainfall_RandomWalk),
                         data = data,
                         # inits = init,
                         n.chains = 3)

jags.out   <- coda.samples (model = j.model,
                            variable.names = c("x","tau_add","tau_obs"),
                            n.iter = 10000)

burnin = 1000                                   ## determine convergence
jags.burn <- window(jags.out, start = burnin)  ## remove burn-in

```

The rainfall data and confidence interval was visualzed.

```{r, eval = FALSE, echo = T, warning = FALSE}

# Plot data and confidence interval
time.rng = c(1,length(time))       ## adjust to zoom in and out
out <- as.matrix(jags.out)         ## convert from coda to matrix  
x.cols <- grep("^x",colnames(out)) ## grab all columns that start with the letter x
ci <- apply(exp(out[,x.cols]),2,quantile,c(0.025,0.5,0.975)) ## model was fit on log scale

plot(time,ci[2,],type='n',ylim=range(y,na.rm=TRUE),ylab="Streamflow average", log='y', xlim=time[time.rng])
## adjust x-axis label to be monthly if zoomed
if(diff(time.rng) < 100){ 
  axis.Date(1, at=seq(time[time.rng[1]],time[time.rng[2]],by='month'), format = "%Y-%m")
}
ecoforecastR::ciEnvelope(time,ci[1,],ci[3,],col=ecoforecastR::col.alpha("lightBlue",0.75)) # add confidence interval 
# add data points
included <- !is.na(y)
heldout <- is.na(y)
# Plot included data points (model saw these)
points(time[included], y[included], pch="+", col='black', cex=0.6)  # filled black dots
# Plot held-out data points (model did NOT see these)
points(time[heldout], z[heldout], pch=1, col='red', cex=0.8)       # open red circles 

```


--Step 5: Forecast the Streamflow Daily Data--

The missing rainfall data was modeled and a seasonality component added to the model.

```{r, eval = FALSE, echo = T, warning = FALSE}

#Add a seasonality component
doy <- as.numeric(format(time, "%j")) / 365  # day of year scaled 0–1
season_sin <- sin(2 * pi * doy)
season_cos <- cos(2 * pi * doy)

# #Identify missing values in rainfall
rain <- cal_ddat$rainfall_dayback

# # Track missing rainfall values
is_na_rain <- is.na(rain)
n_missing <- sum(is_na_rain)
missing_idx <- which(is_na_rain)

```

The model was defined and run through JAGS.

```{r, eval = FALSE, echo = T, warning = FALSE}

RandomWalk_rain_decay <- "
model {

  # Observation model
  for(t in 1:n){
    y[t] ~ dnorm(x[t], tau_obs)
  }

  # Process model with autoregressive decay and covariates
  for(t in 2:n){
    mu[t] <- mu0 + beta_decay * (x[t-1] - mu0) + 
             beta_rain * rain[t] + 
             beta_season_sin * season_sin[t] + 
             beta_season_cos * season_cos[t]
    
    x[t] ~ dnorm(mu[t], tau_add)
  }

  # Impute missing rain values
  for(i in 1:n_missing){
    rain[missing_idx[i]] ~ dnorm(mu_rain, tau_rain)
  }

  # Priors
  mu0 ~ dnorm(0, 0.001)                     # Mean log-streamflow level
  x[1] ~ dnorm(mu0, tau_ic)                 # Initial latent state
  
  tau_obs ~ dgamma(a_obs, r_obs)            # Observation error
  tau_add ~ dgamma(a_add, r_add)            # Process error

  beta_decay ~ dunif(0, 1)                  # AR(1) coefficient bounded for stability
  beta_rain ~ dnorm(0, 0.01)
  beta_season_sin ~ dnorm(0, 0.01)
  beta_season_cos ~ dnorm(0, 0.01)

  mu_rain ~ dnorm(0, 0.01)                  # Mean log-rainfall for imputation
  tau_rain ~ dgamma(1, 1)                   # Rainfall imputation variance
}
"

data <- list(
  y = y_log,
  rain = log(rain+1),               # vector with NAs
  missing_idx = missing_idx,     # indices to impute
  n_missing = n_missing,         # how many to impute
  n = length(y),
  #  x_ic = log(0.1),
  tau_ic = 0.1,
  a_obs = 1,
  r_obs = 1,
  a_add = 1,
  r_add = 1, 
  season_sin = season_sin,      
  season_cos = season_cos )

# Run the model
j.model <- jags.model(file = textConnection(RandomWalk_rain_decay),
                      data = data,
                      n.chains = 3)

```

The convergence was checked.

```{r, eval = FALSE, echo = T, warning = FALSE}

# First convergence check
jags.out <- coda.samples(model = j.model,
                         variable.names = c("tau_add", "tau_obs", "beta_rain", "beta_decay", "mu_rain", "tau_rain"),
                         n.iter = 1000)
plot(jags.out) # traceplot and density check


# Full posterior sampling
jags.out <- coda.samples(model = j.model,
                         variable.names = c("x", "tau_add", "tau_obs", "beta_rain", "beta_decay", "mu_rain", "tau_rain", "rain"),,
                         n.iter = 5000)


# Remove burn-in
burnin <- 1000
jags.burn <- window(jags.out, start = burnin)

```

The ouput of the model was visualized.

```{r, eval = FALSE, echo = T, warning = FALSE}

# Plot data and confidence interval
time.rng = c(1,length(time))       ## adjust to zoom in and out
out <- as.matrix(jags.out)         ## Convert MCMC output to matrix
x.cols <- grep("^x",colnames(out)) ## grab all columns that start with the letter x
ci <- apply(exp(out[,x.cols]),2,quantile,c(0.025,0.5,0.975)) ## model was fit on log scale

plot(time,ci[2,],type='n',ylim=range(y,na.rm=TRUE),ylab="Streamflow average (m³/s)", log='y', xlim=time[time.rng], xlab = "Date",
     main = "Forecast with Rainfall + Seasonality + Decay")

## adjust x-axis label to be monthly if zoomed
if(diff(time.rng) < 100){ 
  axis.Date(1, at=seq(time[time.rng[1]],time[time.rng[2]],by='month'), format = "%Y-%m")
}

ecoforecastR::ciEnvelope(time,ci[1,],ci[3,],col=ecoforecastR::col.alpha("lightblue",0.75)) # add confidence interval 

# add line for mean prediction
forecast_period <- time >= as.Date("2024-01-01")
lines(time[forecast_period], ci[2, forecast_period], col = "blue", lwd = 2)

# Plot observed data
included <- !is.na(y)
heldout <- is.na(y)
# Plot included data points (model saw these)
points(time[included], y[included], pch="+", col='black', cex=0.6)  # filled black dots
# Plot held-out data points (model did NOT see these)
points(time[heldout], z[heldout], pch=1, col='red', cex=0.8)       # open red circles 

```


--Step 6: Validate Against the Held Out Data--



```{r, eval = FALSE, echo = T, warning = FALSE}



```







```{r eval=FALSE, echo=T, warning=FALSE}
#Change the stuff above if you want to:
# eval = F: Doesn't run the code (useful if it's just installing packages or you have saved the outputs already)
# echo = T: Show the outputs in the markdown output
# warning = F: Don't display R warnings
#...

# Read daily metadata and display
dmdat <- read_csv("data/metadata_daily_2025-07-09.csv")

# Read daily data
ddat <- read_csv("data/data_daily_cleaned.csv")

```



If you knit this (knit button above), it will produce a .md document that GitHub can read